# Vision-Language AI Agent

## Overview
A multi-modal AI system that generates image-to-text explanations and answers questions about diagrams, charts, and screenshots. Built using BLIP (as a LLaVA backbone) and LLMs.

## Features
- Image captioning for diagrams, charts, and screenshots
- Contextual question answering (prototype)
- Demonstrates applicability for technical documentation and accessibility solutions

## How to Run
1. Open `Vision_Language_AI_Agent.ipynb` in Google Colab
2. Install required packages (or use `requirements.txt`)
3. Upload images and run each cell in order

## Example
**Image 1 caption:** a col of pictures of a woman in a room
